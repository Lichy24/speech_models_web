{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPZiq3ScfLuG",
        "outputId": "ff356900-460f-4d8d-8aec-c1c463ead3db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import torch\n",
        "import torchaudio\n",
        "import os\n",
        "from torch.nn.functional import normalize\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3ZsbwMl0ozw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOWMe7TthQcz"
      },
      "outputs": [],
      "source": [
        "\n",
        "pickle_in_y = open(\"/content/drive/MyDrive/1_new/law/all_y_train.pickle\",\"rb\")\n",
        "y_train = pickle.load(pickle_in_y)\n",
        "pickle_in_y.close()\n",
        "pickle_in_y1 = open(\"/content/drive/MyDrive/1_new/law/all_y_test.pickle\",\"rb\")\n",
        "y_test = pickle.load(pickle_in_y1)\n",
        "pickle_in_y1.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JUmMiiohZwS"
      },
      "outputs": [],
      "source": [
        "x_train_z = []\n",
        "x_test_z = []\n",
        "\n",
        "x_to_add = open(\"/content/drive/MyDrive/1_new/law/all_x_train.pickle\",\"rb\")\n",
        "x_train = pickle.load(x_to_add)\n",
        "x_to_add.close()\n",
        "\n",
        "x_to_add1 = open(\"/content/drive/MyDrive/1_new/law/all_x_test.pickle\",\"rb\")\n",
        "x_test = pickle.load(x_to_add1)\n",
        "x_to_add1.close()\n",
        "\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NYlGY04hqWb",
        "outputId": "e2a4b0e0-ffc9-487f-ec97-86c6d9717bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11950, 1, 149, 32])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2957, 1, 149, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        " \n",
        "my_tensor = torch.cat(x_train)\n",
        "my_tensor = torch.unsqueeze(my_tensor, 1)\n",
        "print(my_tensor.shape)\n",
        "\n",
        "\n",
        "norm_x_test = torch.cat(x_test)\n",
        "tensor_test = torch.unsqueeze(norm_x_test, 1)\n",
        "tensor_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhk3ukYntOEO",
        "outputId": "3bf5a984-0a0f-419b-defa-8ece45bba53a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eu': 0, 'de': 1, 'es': 2, 'ca': 3, 'fr': 4, 'zh-CN': 5, 'en': 6}\n"
          ]
        }
      ],
      "source": [
        "temp_dickt = {'eu': 0, 'de': 1, 'es': 2, 'ca': 3, 'fr': 4, 'zh-CN': 5, 'en': 6}\n",
        "# for i, x in enumerate(set(y_test)):\n",
        "#   temp_dickt[x] = i \n",
        "# {'eu': 0, 'de': 1, 'es': 2, 'ca': 3, 'fr': 4, 'zh-CN': 5, 'en': 6}\n",
        "y_train_num = torch.FloatTensor([temp_dickt[x] for x in y_train])\n",
        "y_test_num = torch.FloatTensor([temp_dickt[x] for x in y_test])\n",
        "print(temp_dickt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEDZcxDoIBRH",
        "outputId": "8a07eed0-eabe-4157-b555-b17210771173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.0    624\n",
              "0.0    488\n",
              "3.0    420\n",
              "6.0    409\n",
              "2.0    377\n",
              "1.0    345\n",
              "4.0    294\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "pd.DataFrame(y_test_num).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlEewgwgoOzy"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "DROP_OUT = 0.3\n",
        "\n",
        "\n",
        "\n",
        "class Convolutional_Speaker_Identification(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_2d_1 = nn.Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=1)\n",
        "        self.bn_1 = nn.BatchNorm2d(96)\n",
        "        self.max_pool_2d_1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(1, 1))\n",
        "\n",
        "        self.conv_2d_2 = nn.Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
        "        self.bn_2 = nn.BatchNorm2d(256)\n",
        "        self.max_pool_2d_2 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2))\n",
        "\n",
        "        self.conv_2d_3 = nn.Conv2d(256, 384, kernel_size=(3, 3), padding=1)\n",
        "        self.bn_3 = nn.BatchNorm2d(384)\n",
        "\n",
        "        self.conv_2d_4 = nn.Conv2d(384, 256, kernel_size=(3, 3), padding=1)\n",
        "        self.bn_4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_2d_5 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=1)\n",
        "        self.bn_5 = nn.BatchNorm2d(256)\n",
        "        self.max_pool_2d_3 = nn.MaxPool2d(kernel_size=(5, 3), stride=(3, 2))\n",
        "\n",
        "        self.conv_2d_6 = nn.Conv2d(256, 4096, kernel_size=(9, 1), padding=0)\n",
        "        self.drop_1 = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.global_avg_pooling_2d = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dense_1 = nn.Linear(4096, 1024)\n",
        "        self.drop_2 = nn.Dropout(p=DROP_OUT)\n",
        "\n",
        "        self.dense_2 = nn.Linear(1024, 7)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        x = nn.ReLU()(self.conv_2d_1(X))\n",
        "        x = self.bn_1(x)\n",
        "        x = self.max_pool_2d_1(x)\n",
        "\n",
        "        x = nn.ReLU()(self.conv_2d_2(x))\n",
        "        x = self.bn_2(x)\n",
        "        x = self.max_pool_2d_2(x)\n",
        "\n",
        "        x = nn.ReLU()(self.conv_2d_3(x))\n",
        "        x = self.bn_3(x)\n",
        "\n",
        "        x = nn.ReLU()(self.conv_2d_4(x))\n",
        "        x = self.bn_4(x)\n",
        "\n",
        "        x = nn.ReLU()(self.conv_2d_5(x))\n",
        "        x = self.bn_5(x)\n",
        "        x = self.max_pool_2d_3(x)\n",
        "\n",
        "        x = nn.ReLU()(self.conv_2d_6(x))\n",
        "        x = self.drop_1(x)\n",
        "        x = self.global_avg_pooling_2d(x)\n",
        "\n",
        "        x = x.view(-1, x.shape[1])  # output channel for flatten before entering the dense layer\n",
        "        x = nn.ReLU()(self.dense_1(x))\n",
        "        x = self.drop_2(x)\n",
        "\n",
        "        x = self.dense_2(x)\n",
        "        y = nn.LogSoftmax(dim=1)(x)   # consider using Log-Softmax\n",
        "\n",
        "        return y\n",
        "\n",
        "    def get_epochs(self):\n",
        "        return 30\n",
        "\n",
        "    def get_learning_rate(self):\n",
        "        return 0.000005\n",
        "\n",
        "    def get_batch_size(self):\n",
        "        return 32\n",
        "\n",
        "    def to_string(self):\n",
        "        return \"Convolutional_Speaker_Identification_Log_Softmax_Model-epoch_\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEYDmbT_wVFL",
        "outputId": "e469d77f-268a-4c31-f5e6-1cd007e01caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0)tensor(1.2566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 36.95 %\n",
            "1)tensor(0.9690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2)tensor(0.7625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3)tensor(0.7406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 68.14 %\n",
            "4)tensor(0.6270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "5)tensor(0.4381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6)tensor(0.4081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 73.22 %\n",
            "7)tensor(0.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8)tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "9)tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 77.63 %\n",
            "10)tensor(0.1421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "11)tensor(0.0955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12)tensor(0.0777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 76.61 %\n",
            "13)tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14)tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "15)tensor(0.0222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 78.64 %\n",
            "16)tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "17)tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18)tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Test accuracy score: 80.34 %\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Convolutional_Speaker_Identification().to(device)\n",
        "\n",
        "\n",
        "weights = torch.FloatTensor(list(100.0 / pd.DataFrame(y_train).value_counts())).to(device)\n",
        "learning_rate = model.get_learning_rate()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(weight= weights)\n",
        "epoch, batch_size = model.get_epochs(), model.get_batch_size()\n",
        "\n",
        "sample_size = y_train_num.shape[0]\n",
        "\n",
        "batchs = math.ceil(sample_size/batch_size)\n",
        "model.train()\n",
        "for e in range(epoch):\n",
        "  \n",
        "  for i in range(batchs):\n",
        "    min = i*batch_size\n",
        "    max = i*batch_size + batch_size\n",
        "\n",
        "    if i*batch_size + batch_size > sample_size:\n",
        "      max = sample_size\n",
        "    \n",
        "    X = my_tensor[min:max].to(device)\n",
        "    y = y_train_num[min:max].long().to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    output = model(X)\n",
        "    loss = criterion(output, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_acc = torch.sum(torch.argmax(output, dim = 1) == y)\n",
        "\n",
        "  print(str(e)+\")\" + str(loss))\n",
        "\n",
        "  if e%3 == 0:\n",
        "    model.eval()\n",
        "    y_p = np.argmax(model(tensor_test[:int(len(tensor_test)*0.1)].to(device)).to(\"cpu\").detach().numpy(), axis =1)\n",
        "    y_true = np.array(y_test_num[:int(len(tensor_test)*0.1)], dtype= int)\n",
        "\n",
        "    acc = np.mean(np.array(y_p == y_true, dtype= int))\n",
        "    print(\"Test accuracy score:\", round(acc*100,2) , \"%\")\n",
        "    if round(acc*100,2) >80.0:\n",
        "      break;\n",
        "    model.train()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-AWZxdQ--2X"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), \"/content/drive/MyDrive/voice/\"+llen+\"stat1.pth\")\n",
        "torch.save(model, \"/content/drive/MyDrive/1_new/model/enmodel0.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqcLyVCUHTn7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "lan gpunet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}